diff --git a/.vscode/settings.json b/.vscode/settings.json
new file mode 100644
index 0000000..d6529bc
--- /dev/null
+++ b/.vscode/settings.json
@@ -0,0 +1,13 @@
+{
+    "files.associations": {
+        "assert.h": "c",
+        "defs.h": "c",
+        "riscv.h": "c",
+        "memlayout.h": "c",
+        "thread_spinlock.h": "c",
+        "param.h": "c",
+        "proc.h": "c",
+        "thread_sem.h": "c",
+        "thread_cv.h": "c"
+    }
+}
\ No newline at end of file
diff --git a/Makefile b/Makefile
index 39a99d7..a822569 100644
--- a/Makefile
+++ b/Makefile
@@ -132,6 +132,8 @@ UPROGS=\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
+	$U/_threads\
+	$U/_producer_consumer\
 
 fs.img: mkfs/mkfs README $(UPROGS)
 	mkfs/mkfs fs.img README $(UPROGS)
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..752d3b8 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -106,6 +106,13 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
+int             thread_create(uint64 fcn, uint64 arg, uint64 stack);
+int             thread_join(int thread_id);
+void            thread_exit();
+void            thread_freepagetable(pagetable_t pagetable, uint64 sz);
+void            release_through_kernel(uint64 lock);
+void            release_and_sleep(uint64 lock);
+void            thread_wakeup(int thread_id);
 
 // swtch.S
 void            swtch(struct context*, struct context*);
@@ -165,7 +172,11 @@ void            uvmfirst(pagetable_t, uchar *, uint);
 uint64          uvmalloc(pagetable_t, uint64, uint64, int);
 uint64          uvmdealloc(pagetable_t, uint64, uint64);
 int             uvmcopy(pagetable_t, pagetable_t, uint64);
+int             uvmmirror(pagetable_t, pagetable_t, uint64);
+int             uvmrangemirror(pagetable_t, pagetable_t, uint64, uint64);
 void            uvmfree(pagetable_t, uint64);
+void            thread_uvmfree(pagetable_t, uint64);
+void            freewalk(pagetable_t);
 void            uvmunmap(pagetable_t, uint64, uint64, int);
 void            uvmclear(pagetable_t, uint64);
 pte_t *         walk(pagetable_t, uint64, int);
@@ -173,6 +184,7 @@ uint64          walkaddr(pagetable_t, uint64);
 int             copyout(pagetable_t, uint64, char *, uint64);
 int             copyin(pagetable_t, char *, uint64, uint64);
 int             copyinstr(pagetable_t, char *, uint64, uint64);
+int             mycopyout(pagetable_t pagetable, uint64 dstva);
 
 // plic.c
 void            plicinit(void);
diff --git a/kernel/exec.c b/kernel/exec.c
index e18bbb6..4d585af 100644
--- a/kernel/exec.c
+++ b/kernel/exec.c
@@ -19,120 +19,198 @@ int flags2perm(int flags)
     return perm;
 }
 
+//completes the work of the sys_exec() syscall
+//path -> executable file path: /usr/bin/cat
+//argv -> pointer to the argument strings needed for main() of that file [null terminated]
+//returns -1 if something goes wrong
+//but if all ok, then it begins executing that executable file in the new virtual address space of kernel
 int
 exec(char *path, char **argv)
 {
   char *s, *last;
   int i, off;
   uint64 argc, sz = 0, sp, ustack[MAXARG], stackbase;
+  //sz = 0 -> load the program segments into a new virtual address space (created later in this function) starting from virtual address 0
   struct elfhdr elf;
+
+  //an inode (short for "index node") is a fundamental data structure used to represent files. It contains metadata about a file, such as its type, permissions, size, and pointers to the data blocks that hold the file's content. Each inode is identified by a unique inode number, which is often used to reference the inode within the file system. Inodes are typically organized in an inode table or similar structure within the file system. This table allows the operating system to quickly look up and access inodes.
   struct inode *ip;
-  struct proghdr ph;
+  struct proghdr ph;    //program header data structure
   pagetable_t pagetable = 0, oldpagetable;
   struct proc *p = myproc();
 
-  begin_op();
+  begin_op();   //begin transaction
 
+  //namei() -> Look up and return the pointer to the inode for given path name of an executable file.
   if((ip = namei(path)) == 0){
-    end_op();
+    end_op();   //end transaction
     return -1;
   }
   ilock(ip);
 
-  // Check ELF header
-  if(readi(ip, 0, (uint64)&elf, 0, sizeof(elf)) != sizeof(elf))
+  // Read data from inode.
+  // Caller must hold ip->lock.
+  // If user_dst==1, then dst is a user virtual address;
+  // otherwise, dst is a kernel address.
+  // int readi(struct inode *ip, int user_dst, uint64 dst, uint off, uint n)
+  if(readi(ip, 0, (uint64)&elf, 0, sizeof(elf)) != sizeof(elf)) // Check ELF header
     goto bad;
 
+  //we read in from offset 0 [of the ipnode 'ip'] the elf header into local variable elf that points to a location in kernel-address-space
+
   if(elf.magic != ELF_MAGIC)
     goto bad;
 
+  //Now, this code is executing within a process, and that process has a virtual address space. If anything goes wrong, we have to return -1 and return to executing the code that is in that virt addr space.
+  //But if all ok, we are going to create a new user virtual address space, and load the executable file into that address space. So, now we are going to create that second virtual address space. The local variable pagetable will point to the newly created pagetable.
+  //The function proc_pagetable() needs to add a trapframe to the top of the new virtual address space and it needs to know which physical page to use for that particular page in the virtual address space.
+  //The executable file must be loaded into the 'code segment' of this new virtual address space
+
+  //proc_pagetable() -> Create a user page table for a given process, with no user memory, but with trampoline and trapframe pages.
   if((pagetable = proc_pagetable(p)) == 0)
     goto bad;
 
-  // Load program into memory.
+  //Load executable file into memory segment-by-segment. Each program segment may cover many pages.
+  //elf.phoff -> offset of the first program header
+  //elf.phnum -> total number of program headers
   for(i=0, off=elf.phoff; i<elf.phnum; i++, off+=sizeof(ph)){
+    //from 'off' offset of ipnode, read-in the program-segment of size 'sizeof(ph)' bytes into the local variable 'ph'
     if(readi(ip, 0, (uint64)&ph, off, sizeof(ph)) != sizeof(ph))
       goto bad;
     if(ph.type != ELF_PROG_LOAD)
       continue;
+
+    //when the program is loaded into memory, it will be allocated a memory of size memsz which is at least as large as filesz
     if(ph.memsz < ph.filesz)
       goto bad;
+
+    //check overflow, vaddr and memsz are unsigned integers
     if(ph.vaddr + ph.memsz < ph.vaddr)
       goto bad;
+
+    //check if the virtual address we will be loading the executable file into is page-aligned
     if(ph.vaddr % PGSIZE != 0)
       goto bad;
+
     uint64 sz1;
+
+    //Allocate PTEs and physical memory to grow virtual address space  from oldsz to
+    //newsz, which need not be page aligned. Returns new size or 0 on error. The newly created virtual address space must be at least large enough to hold the program segment
+    // uint64 uvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz, int xperm)
     if((sz1 = uvmalloc(pagetable, sz, ph.vaddr + ph.memsz, flags2perm(ph.flags))) == 0)
       goto bad;
+
+    //flags2perm()
+    //Each user-page is by default user-accessible and readable. With this helper function, we can specify whether this new virtual address space will be writable and/or executable.
+
+    //update local variable sz. why??
+    //Because we are executing A SINGLE PROGRAM DIVIDED INTO MANY PROGRAM SEGMENTS and we have created A SINGLE 'pagetable'/virtual-address-space for the whole program. So, each time this virt addr space grows, we must update its current size, because this will be the oldsize for the next program segment.
     sz = sz1;
+
+    //now we have created space for the current program segment in the new virtual address space. Next, load the bytes from the file to the virtual address space.
+    //ph.off -> where in the elf file, the bytes of current segment begin
+    //move the segment at location 'ph.vaddr' in virt addr space and update PTEs in 'pagetable'
     if(loadseg(pagetable, ph.vaddr, ip, ph.off, ph.filesz) < 0)
       goto bad;
   }
+
+  //we are done loading the executable file in new virt addr space corresponding to 'pagetable'
   iunlockput(ip);
   end_op();
   ip = 0;
 
   p = myproc();
-  uint64 oldsz = p->sz;
+  uint64 oldsz = p->sz;   //size of the virtual address space of current process
+
+  // now we have, in our new virtual address space, trampoline and trapframe, located at the top and all the program segments located at the bottom. But the final location of the ending position of the loaded segments ['sz'] may not be page aligned.
 
   // Allocate two pages at the next page boundary.
   // Make the first inaccessible as a stack guard.
   // Use the second as the user stack.
+  // From now on, 'the stack'/'stack' will refer to this user stack.
   sz = PGROUNDUP(sz);
   uint64 sz1;
   if((sz1 = uvmalloc(pagetable, sz, sz + 2*PGSIZE, PTE_W)) == 0)
     goto bad;
   sz = sz1;
+
+  //the guard page must be inaccessible to user, so make sure that stack never grows below stackbase
   uvmclear(pagetable, sz-2*PGSIZE);
-  sp = sz;
-  stackbase = sp - PGSIZE;
+  sp = sz;                  //top of the stack
+  stackbase = sp - PGSIZE;  //bottom of the stack
 
+  //this function is called from syscall sys_exec(), which passes an array, argv, of string pointers that point to the argument strings [originally provided by user] located at seaprate pages in kernel space
   // Push argument strings, prepare rest of stack in ustack.
+  //STACK GROWS DOWNWARD, THAT IS, FROM A HIGHER ADDRESS TO A LOWER ADDRESS
+  //this loop fetches all argument strings from argv array and pushes them onto the stack
   for(argc = 0; argv[argc]; argc++) {
     if(argc >= MAXARG)
       goto bad;
     sp -= strlen(argv[argc]) + 1;
     sp -= sp % 16; // riscv sp must be 16-byte aligned
+
+    //if stack grows below stackbase, that is, overflows, error
     if(sp < stackbase)
       goto bad;
+
+    //copy strings from argv[argc] to sp and update pagetable
     if(copyout(pagetable, sp, argv[argc], strlen(argv[argc]) + 1) < 0)
       goto bad;
+
+    //we want to save a pointer to the string just pushed onto the stack, hence the local variable ustack
     ustack[argc] = sp;
   }
   ustack[argc] = 0;
 
   // push the array of argv[] pointers.
-  sp -= (argc+1) * sizeof(uint64);
+  sp -= (argc+1) * sizeof(uint64);  //+1 for the null string in ustack
   sp -= sp % 16;
+
+  //if stack grows below stackbase, that is, overflows, error
   if(sp < stackbase)
     goto bad;
+
+  //copy strings from array ustack to sp and update pagetable
   if(copyout(pagetable, sp, (char *)ustack, (argc+1)*sizeof(uint64)) < 0)
     goto bad;
 
+  //now, sp points to the starting position of ustack array. Thus, when we will call the main() function for the executable file/program, we will pass argc in a0 and sp in a1
+
   // arguments to user main(argc, argv)
   // argc is returned via the system call return
   // value, which goes in a0.
   p->trapframe->a1 = sp;
 
   // Save program name for debugging.
+  //path-> usr/bin/echo
+  //               |
+  //              \|/
+  //              last
   for(last=s=path; *s; s++)
     if(*s == '/')
       last = s+1;
   safestrcpy(p->name, last, sizeof(p->name));
+
+  //now we are ready to switch from the old virtual address space where this code is running to the new virtual address space created previously for the program and make sure we start at the beginning of the new program
     
   // Commit to the user image.
   oldpagetable = p->pagetable;
   p->pagetable = pagetable;
   p->sz = sz;
   p->trapframe->epc = elf.entry;  // initial program counter = main
-  p->trapframe->sp = sp; // initial stack pointer
+  p->trapframe->sp = sp;          // initial stack pointer
   proc_freepagetable(oldpagetable, oldsz);
 
   return argc; // this ends up in a0, the first argument to main(argc, argv)
+  //even after return of the sys_exec(), this user program continues execution starting from elf.entry
+  //the new program executes with all the files that were open in the previous program still open and in the same cwd since the fields ofile and cwd of myproc() is unchanged
 
  bad:
+  //since we don't know at which point we got a 'bad' result, check if we have reached far enough to allocate a pagetable. If yes, free that pagetable as well as the data pages of total size 'sz'
   if(pagetable)
     proc_freepagetable(pagetable, sz);
+
+  //if inode for the executable file still open
   if(ip){
     iunlockput(ip);
     end_op();
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..faadb4a 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -13,7 +13,9 @@ struct proc proc[NPROC];
 struct proc *initproc;
 
 int nextpid = 1;
+int next_mem_id = 1;
 struct spinlock pid_lock;
+struct spinlock mem_id_lock;
 
 extern void forkret(void);
 static void freeproc(struct proc *p);
@@ -51,10 +53,12 @@ procinit(void)
   
   initlock(&pid_lock, "nextpid");
   initlock(&wait_lock, "wait_lock");
+  initlock(&mem_id_lock, "mem_id_lock");
   for(p = proc; p < &proc[NPROC]; p++) {
       initlock(&p->lock, "proc");
       p->state = UNUSED;
       p->kstack = KSTACK((int) (p - proc));
+      initlock(&p->memlock, "memlock");
   }
 }
 
@@ -102,6 +106,19 @@ allocpid()
   return pid;
 }
 
+int
+allocmemid()
+{
+  int mem_id;
+
+  acquire(&mem_id_lock);
+  mem_id = next_mem_id;
+  next_mem_id = next_mem_id + 1;
+  release(&mem_id_lock);
+
+  return mem_id;
+}
+
 // Look in the process table for an UNUSED proc.
 // If found, initialize state required to run in the kernel,
 // and return with p->lock held.
@@ -123,6 +140,7 @@ allocproc(void)
 
 found:
   p->pid = allocpid();
+  p->mem_id = allocmemid();
   p->state = USED;
 
   // Allocate a trapframe page.
@@ -132,8 +150,8 @@ found:
     return 0;
   }
 
-  // An empty user page table.
   p->pagetable = proc_pagetable(p);
+
   if(p->pagetable == 0){
     freeproc(p);
     release(&p->lock);
@@ -158,8 +176,10 @@ freeproc(struct proc *p)
   if(p->trapframe)
     kfree((void*)p->trapframe);
   p->trapframe = 0;
-  if(p->pagetable)
-    proc_freepagetable(p->pagetable, p->sz);
+  if(p->pagetable){
+    if(!p->is_thread) proc_freepagetable(p->pagetable, p->sz);
+    else  thread_freepagetable(p->pagetable, p->sz);
+  }
   p->pagetable = 0;
   p->sz = 0;
   p->pid = 0;
@@ -215,6 +235,14 @@ proc_freepagetable(pagetable_t pagetable, uint64 sz)
   uvmfree(pagetable, sz);
 }
 
+void
+thread_freepagetable(pagetable_t pagetable, uint64 sz)
+{
+  uvmunmap(pagetable, TRAMPOLINE, 1, 0);
+  uvmunmap(pagetable, TRAPFRAME, 1, 0);
+  thread_uvmfree(pagetable, sz);
+}
+
 // a user program that calls exec("/init")
 // assembled from ../user/initcode.S
 // od -t xC ../user/initcode
@@ -261,16 +289,33 @@ growproc(int n)
 {
   uint64 sz;
   struct proc *p = myproc();
+  acquire(&p->memlock);
 
   sz = p->sz;
   if(n > 0){
     if((sz = uvmalloc(p->pagetable, sz, sz + n, PTE_W)) == 0) {
+      release(&p->memlock);
       return -1;
     }
   } else if(n < 0){
     sz = uvmdealloc(p->pagetable, sz, sz + n);
   }
   p->sz = sz;
+
+  struct proc *q;
+  for(q = proc; q < &proc[NPROC]; q++){
+    if(q->mem_id == p->mem_id && q->pid != p->pid){
+      if(n >= 0){
+        uvmrangemirror(p->pagetable, q->pagetable, q->sz, sz);
+      }
+      else{
+        uvmunmap(q->pagetable, PGROUNDUP(sz), (PGROUNDUP(q->sz)-PGROUNDUP(sz))/PGSIZE, 1);
+      }
+      q->sz = sz;
+    }
+  }
+
+  release(&p->memlock);
   return 0;
 }
 
@@ -288,7 +333,6 @@ fork(void)
     return -1;
   }
 
-  // Copy user memory from parent to child.
   if(uvmcopy(p->pagetable, np->pagetable, p->sz) < 0){
     freeproc(np);
     release(&np->lock);
@@ -325,6 +369,97 @@ fork(void)
   return pid;
 }
 
+int
+thread_create(uint64 fcn, uint64 arg, uint64 stack)
+{
+  int i, pid;
+  struct proc *np;
+  struct proc *p = myproc();
+
+  if((np = allocproc()) == 0){
+    return -1;
+  }
+
+  if(uvmmirror(p->pagetable, np->pagetable, p->sz) < 0){
+    freeproc(np);
+    release(&np->lock);
+    return -1;
+  }
+
+  np->sz = p->sz;
+  *(np->trapframe) = *(p->trapframe);
+  np->trapframe->a0 = arg;
+  np->trapframe->epc = fcn;
+  np->trapframe->sp = stack + PGSIZE;
+  np->trapframe->sp -= np->trapframe->sp % 16;
+  np->is_thread = 1;
+  np->mem_id = p->mem_id;
+
+  // p->trapframe->a0 = arg;
+
+  for(i = 0; i < NOFILE; i++)
+    if(p->ofile[i])
+      np->ofile[i] = filedup(p->ofile[i]);
+  np->cwd = idup(p->cwd);
+
+  safestrcpy(np->name, p->name, sizeof(p->name));
+
+  pid = np->pid;
+
+  release(&np->lock);
+
+  acquire(&wait_lock);
+  np->parent = p;
+  release(&wait_lock);
+
+  acquire(&np->lock);
+  np->state = RUNNABLE;
+  release(&np->lock);
+
+  return pid;
+}
+
+int
+thread_join(int thread_id)
+{
+  struct proc *pp;
+  int havekids, pid;
+  struct proc *p = myproc();
+
+  acquire(&wait_lock);
+
+  for(;;){
+    // Scan through table looking for exited children.
+    havekids = 0;
+    for(pp = proc; pp < &proc[NPROC]; pp++){
+      if(pp->parent == p && pp->is_thread == 1 && pp->pid == thread_id){
+        // make sure the child isn't still in exit() or swtch().
+        acquire(&pp->lock);
+
+        havekids = 1;
+        if(pp->state == ZOMBIE){
+          // Found one.
+          pid = pp->pid;
+          freeproc(pp);
+          release(&pp->lock);
+          release(&wait_lock);
+          return pid;
+        }
+        release(&pp->lock);
+      }
+    }
+
+    // No point waiting if we don't have any children.
+    if(!havekids || killed(p)){
+      release(&wait_lock);
+      return -1;
+    }
+
+    // Wait for a child to exit.
+    sleep(p, &wait_lock);  //DOC: wait-sleep
+  }
+}
+
 // Pass p's abandoned children to init.
 // Caller must hold wait_lock.
 void
@@ -340,6 +475,48 @@ reparent(struct proc *p)
   }
 }
 
+void
+thread_exit()
+{
+  struct proc *p = myproc();
+
+  if(p == initproc)
+    panic("init exiting");
+
+  // Close all open files.
+  for(int fd = 0; fd < NOFILE; fd++){
+    if(p->ofile[fd]){
+      struct file *f = p->ofile[fd];
+      fileclose(f);
+      p->ofile[fd] = 0;
+    }
+  }
+
+  begin_op();
+  iput(p->cwd);
+  end_op();
+  p->cwd = 0;
+
+  acquire(&wait_lock);
+
+  // Give any children to init.
+  reparent(p);
+
+  // Parent might be sleeping in wait().
+  wakeup(p->parent);
+
+  acquire(&p->lock);
+
+  p->xstate = 0;
+  p->state = ZOMBIE;
+
+  release(&wait_lock);
+
+  // Jump into the scheduler, never to return.
+  sched();
+  panic("zombie exit");
+}
+
 // Exit the current process.  Does not return.
 // An exited process remains in the zombie state
 // until its parent calls wait().
@@ -561,6 +738,28 @@ sleep(void *chan, struct spinlock *lk)
   acquire(lk);
 }
 
+void
+release_through_kernel(uint64 lock) {
+  mycopyout(myproc()->pagetable, lock);
+}
+
+void
+release_and_sleep(uint64 lock)
+{
+  struct proc *p = myproc();
+
+  acquire(&p->lock);
+  release_through_kernel(lock);
+
+  // Go to sleep.
+  p->state = SLEEPING;
+
+  sched();
+
+  // Reacquire original lock.
+  release(&p->lock);
+}
+
 // Wake up all processes sleeping on chan.
 // Must be called without any p->lock.
 void
@@ -579,6 +778,23 @@ wakeup(void *chan)
   }
 }
 
+// wake up the thread with id 'thread_id'
+void
+thread_wakeup(int thread_id)
+{
+  struct proc *p;
+
+  for(p = proc; p < &proc[NPROC]; p++) {
+    if(p != myproc()){
+      acquire(&p->lock);
+      if(p->state == SLEEPING && p->pid == thread_id) {
+        p->state = RUNNABLE;
+      }
+      release(&p->lock);
+    }
+  }
+}
+
 // Kill the process with the given pid.
 // The victim won't exit until it tries to return
 // to user space (see usertrap() in trap.c).
diff --git a/kernel/proc.h b/kernel/proc.h
index d021857..7bd3414 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -104,4 +104,7 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+  struct spinlock memlock;	  // find places to set and release the locks
+  int is_thread;               // if it is thread
+  int mem_id;                   // All threads will have the same physical pages with the mothrer, hence the same memory ID
 };
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..9d03635 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,12 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_thread_create(void);
+extern uint64 sys_thread_join(void);
+extern uint64 sys_thread_exit(void);
+extern uint64 sys_thread_release_kernel(void);
+extern uint64 sys_release_and_sleep(void);
+extern uint64 sys_thread_wakeup(void);
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +132,11 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_thread_create]   sys_thread_create,
+[SYS_thread_join]   sys_thread_join,
+[SYS_thread_exit]   sys_thread_exit,
+[SYS_release_and_sleep] sys_release_and_sleep,
+[SYS_thread_wakeup] sys_thread_wakeup,
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..8f44f44 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,8 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_thread_create  22
+#define SYS_thread_join    23
+#define SYS_thread_exit    24
+#define SYS_release_and_sleep 25
+#define SYS_thread_wakeup  26
diff --git a/kernel/sysfile.c b/kernel/sysfile.c
index 16b668c..b56280a 100644
--- a/kernel/sysfile.c
+++ b/kernel/sysfile.c
@@ -431,36 +431,51 @@ sys_chdir(void)
   return 0;
 }
 
+// gets all the arguments[passed as an array of strings] from the address-space of the process that invokes this syscall
 uint64
 sys_exec(void)
 {
   char path[MAXPATH], *argv[MAXARG];
+  //at this point, argv is just an empty array of size MAXARG; located in kernel-address-space.
+  //the goal of this function is to copy all the args currently residing in user-process-address-space to kernel-address-space, that is, gradually fillup argv array. And after filling it with the last user arg, set remaining slots in argv to null.
   int i;
   uint64 uargv, uarg;
 
-  argaddr(1, &uargv);
+  argaddr(1, &uargv);   //copy virtual address[user-space] of the argument array, provided as the second parameter to exec() syscall, to uargv. So, uargv now points to the starting position of the arguments array provided.
+
+  //copy maximum 'MAXPATH' characters into 'path' from the first argument provided.
   if(argstr(0, path, MAXPATH) < 0) {
     return -1;
   }
-  memset(argv, 0, sizeof(argv));
-  for(i=0;; i++){
-    if(i >= NELEM(argv)){
+  memset(argv, 0, sizeof(argv));  //sets all entries of argv to null
+  for(i=0;; i++){              //loop through all the args
+    if(i >= NELEM(argv)){     //'bad' if we have gone past the number of args that can be accommodated
       goto bad;
     }
+
+    //goto the argument at i-th offset from the starting position of uargv and store the location in uarg
     if(fetchaddr(uargv+sizeof(uint64)*i, (uint64*)&uarg) < 0){
       goto bad;
     }
-    if(uarg == 0){
+    if(uarg == 0){    //if we got the last argument provided by the user, set the argv element to null and break the loop
       argv[i] = 0;
       break;
     }
+
+    //as mentioned earlier, the location pointed to by uarg is a virtual address of user process. We need to move them to kernel memory. So, allocate an entire page for storing the current argument pointed to by uarg.
     argv[i] = kalloc();
     if(argv[i] == 0)
       goto bad;
+
+    //now we are done allocating a page in kernel-address-space for argv[i], but the page is empty, we haven't fetched the argument yet. That's what we are doing next.
+
+    //int fetchstr(uint64 addr, char *buf, int max)
+    //There is a string located at virtual adrress addr in current user-proces. Fetch 'max' number of characters from that string into 'buf'
     if(fetchstr(uarg, argv[i], PGSIZE) < 0)
       goto bad;
   }
 
+  //now we have fetched both the path to run the requested executable file and the arguments needed to run that file's main() function. Next, execute the file by calling exec() function. The number of arguments needed for main() function of the program will be returned from exec()
   int ret = exec(path, argv);
 
   for(i = 0; i < NELEM(argv) && argv[i] != 0; i++)
@@ -469,6 +484,7 @@ sys_exec(void)
   return ret;
 
  bad:
+  //in case of unexpected errors, free all the pages created for storing the user-provided arguments
   for(i = 0; i < NELEM(argv) && argv[i] != 0; i++)
     kfree(argv[i]);
   return -1;
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..af38801 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,44 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+uint64
+sys_thread_create(void) {
+  uint64 fcn, arg, stack;
+  argaddr(0, &fcn);
+  argaddr(1, &arg);
+  argaddr(2, &stack);
+
+  return thread_create(fcn, arg, stack);
+}
+
+uint64
+sys_thread_join(void){
+  int tid;
+  argint(0, &tid);
+  return thread_join(tid);
+}
+
+uint64
+sys_thread_exit(void){
+  thread_exit();
+  return 0;
+}
+
+uint64
+sys_release_and_sleep(void)
+{
+  uint64 arg;
+  argaddr(0, &arg);
+  release_and_sleep(arg);
+  return 0;
+}
+
+uint64
+sys_thread_wakeup(void)
+{
+  int tid;
+  argint(0, &tid);
+  thread_wakeup(tid);
+  return 0;
+}
\ No newline at end of file
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..e7fc9b6 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -296,12 +296,21 @@ uvmfree(pagetable_t pagetable, uint64 sz)
   freewalk(pagetable);
 }
 
+void
+thread_uvmfree(pagetable_t pagetable, uint64 sz)
+{
+  if(sz > 0)
+    uvmunmap(pagetable, 0, PGROUNDUP(sz)/PGSIZE, 0);
+  freewalk(pagetable);
+}
+
 // Given a parent process's page table, copy
 // its memory into a child's page table.
 // Copies both the page table and the
 // physical memory.
 // returns 0 on success, -1 on failure.
 // frees any allocated pages on failure.
+// sz -> size of the old virtual address space
 int
 uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
 {
@@ -332,6 +341,57 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   return -1;
 }
 
+//Similar to uvmcopy() except that it doesn't use kalloc() i.e. doesn't allocate new physical pages
+int
+uvmmirror(pagetable_t old, pagetable_t new, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = 0; i < sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmcopy: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmcopy: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    if(mappages(new, i, PGSIZE, (uint64)pa, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+int
+uvmrangemirror(pagetable_t old, pagetable_t new, uint64 sz_old, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = PGROUNDUP(sz_old); i < sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmcopy: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmcopy: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    if(mappages(new, i, PGSIZE, (uint64)pa, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, PGROUNDUP(sz_old), (i - PGROUNDUP(sz_old)) / PGSIZE, 1);
+  return -1;
+}
+
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
 void
@@ -370,6 +430,22 @@ copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)
   return 0;
 }
 
+int
+mycopyout(pagetable_t pagetable, uint64 dstva)
+{
+  uint64 va0, pa0;
+
+  va0 = PGROUNDDOWN(dstva);
+  pa0 = walkaddr(pagetable, va0);
+  if(pa0 == 0)
+    return -1;
+
+  __sync_synchronize();
+  __sync_lock_release((uint8*)(pa0 + (dstva - va0)));
+
+  return 0;
+}
+
 // Copy from user to kernel.
 // Copy len bytes to dst from virtual address srcva in a given page table.
 // Return 0 on success, -1 on error.
diff --git a/run.sh b/run.sh
new file mode 100644
index 0000000..0e3b7c8
--- /dev/null
+++ b/run.sh
@@ -0,0 +1,11 @@
+#!/bin/bash
+if [ $# = 1 ];
+then
+    git add --all; git diff HEAD > ../"${1}"
+    git clean -fdx; git reset --hard
+    git apply --whitespace=fix ../"${1}"
+    make clean; make qemu
+else
+    echo "Usage:"
+    echo "./run.sh <patch-file-name>"
+fi
\ No newline at end of file
diff --git a/user/producer_consumer.c b/user/producer_consumer.c
new file mode 100644
index 0000000..8784dcd
--- /dev/null
+++ b/user/producer_consumer.c
@@ -0,0 +1,118 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/thread_sem.h"
+
+struct queue q;
+// a mutex object lock
+struct thread_mutex mlock;
+// mutex output lock
+struct thread_mutex outlock;
+// a semaphore object empty
+Zem_t __empty__;
+// a semaphore object full
+Zem_t __full__;
+
+void init_semaphore()
+{
+	// initialize mutex lock
+	thread_mutex_init(&mlock, "mutex");
+	thread_mutex_init(&outlock, "outlock");
+	// initialize semaphore empty with 5
+	Zem_init(&__empty__, 5);
+	// initialize semaphore full with 0
+	Zem_init(&__full__, 0);
+}
+
+void ProducerFunc(void * arg)
+{
+	thread_mutex_lock(&outlock);
+	printf("%s\n",(char*)arg);
+	thread_mutex_unlock(&outlock);
+
+	int i;
+	for(i=1;i<=10;i++)
+	{
+		// wait for semphore empty
+		Zem_wait(&__empty__);
+		// wait for mutex lock
+		thread_mutex_lock(&mlock);
+
+		sleep(1);
+		push(&q, i);
+
+		thread_mutex_lock(&outlock);
+		printf("producer produced item %d\n",i);
+		thread_mutex_unlock(&outlock);
+
+		// unlock mutex lock
+		thread_mutex_unlock(&mlock);
+		// post semaphore full
+		Zem_post(&__full__);
+	}
+
+	thread_exit();
+    return;
+}
+
+void ConsumerFunc(void * arg)
+{
+	thread_mutex_lock(&outlock);
+	printf("%s\n",(char*)arg);
+	thread_mutex_unlock(&outlock);
+
+	int i;
+	for(i=1;i<=10;i++)
+	{
+		// wait for semphore full
+		Zem_wait(&__full__);
+		// wait for mutex lock
+		thread_mutex_lock(&mlock);
+
+		sleep(1);
+		int item = front(&q);
+		pop(&q);
+
+		thread_mutex_lock(&outlock);
+		printf("consumer consumed item %d\n",item);
+		thread_mutex_unlock(&outlock);
+
+		// unlock mutex lock
+		thread_mutex_unlock(&mlock);
+		// post semaphore empty
+		Zem_post(&__empty__);
+	}
+
+	thread_exit();
+    return;
+}
+
+int main(void)
+{
+
+	init_semaphore();
+
+	char * message1 = "i am producer";
+	char * message2 = "i am consumer";
+
+
+	void *s1, *s2;
+	int thread1, thread2, r1, r2;
+
+	s1 = malloc(4096);
+	s2 = malloc(4096);
+
+	thread1 = thread_create(ProducerFunc, (void*)message1, s1);
+	thread2 = thread_create(ConsumerFunc, (void*)message2, s2);
+
+	r1 = thread_join(thread1);
+	r2 = thread_join(thread2);
+
+	printf("Threads finished: %d, %d\n", r1, r2);
+
+	exit(0);
+}
+
+// int main() {
+// 	return 0;
+// }
\ No newline at end of file
diff --git a/user/thread_cv.h b/user/thread_cv.h
new file mode 100644
index 0000000..0389fbc
--- /dev/null
+++ b/user/thread_cv.h
@@ -0,0 +1,77 @@
+// Conditional variable
+#include "user/thread_mutex.h"
+
+struct queue{
+    int arr[16];
+	int front;
+	int rear;
+	int size;
+};
+
+void initqueue(struct queue* q)
+{
+    q->front = 0;
+    q->rear = 0;
+    q->size = 0;
+}
+void push(struct queue* q, int x)
+{
+    q->arr[q->rear] = x;
+    q->rear = (q->rear+1)%16;
+    q->size++;
+}
+int front(struct queue* q)
+{
+    if(q->size==0)
+        return -1;
+    return q->arr[q->front];
+}
+void pop(struct queue* q)
+{
+    if(q->size==0) return;
+    q->front = (q->front+1)%16;
+    q->size--;
+}
+
+struct condition {
+    struct queue Q;
+    struct thread_mutex mx; /*protects queue; This semaphore should be a spin-lock since it will only be held for very short periods of time. */
+};
+
+void
+condition_init(struct condition *cond)
+{
+    initqueue(&cond->Q);
+    thread_mutex_init(&cond->mx, "condition_mutex");
+}
+
+void
+cond_wait(struct condition *cv, struct thread_mutex *mx)
+{
+    thread_mutex_lock(&cv->mx);  /* protect the queue */
+    push(&cv->Q, getpid()); /* enqueue */
+    thread_mutex_unlock(&cv->mx); /* we're done with the list */
+
+    mx->pid = 0;
+    release_and_sleep(&mx->locked);
+
+    thread_mutex_lock(mx); /* Woke up -- our turn, get resource lock */
+
+    return;
+}
+
+void
+cond_wakeup(struct condition *cv)
+{
+    int tid;
+
+    thread_mutex_lock(&cv->mx); /* protect the queue */
+    tid = front(&cv->Q);
+    pop(&cv->Q);
+    thread_mutex_unlock(&cv->mx);
+
+    if (tid>0)
+        thread_wakeup(tid);
+
+    return;
+}
diff --git a/user/thread_mutex.h b/user/thread_mutex.h
new file mode 100644
index 0000000..cfb5ae7
--- /dev/null
+++ b/user/thread_mutex.h
@@ -0,0 +1,59 @@
+// Mutual exclusion lock.
+#include "kernel/types.h"
+#include "user/user.h"
+
+struct thread_mutex {
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  char *name;        // Name of lock.
+  int pid;   // The PID of the process holding the lock.
+};
+
+void
+thread_mutex_init(struct thread_mutex *m, char *name)
+{
+  m->name = name;
+  m->locked = 0;
+  m->pid = 0;
+}
+
+// Check whether this cpu is holding the lock.
+// Interrupts must be off.
+int
+thread_holding_mutex(struct thread_mutex *m)
+{
+  int r;
+  r = (m->locked && m->pid == getpid());
+  return r;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_mutex_lock(struct thread_mutex *m)
+{
+  if(thread_holding_mutex(m))
+    exit(0);
+
+  while(__sync_lock_test_and_set(&m->locked, 1) != 0)
+    sleep(1);
+
+  __sync_synchronize();
+
+  m->pid = getpid();
+}
+
+// Release the lock.
+void
+thread_mutex_unlock(struct thread_mutex *m)
+{
+  if(!thread_holding_mutex(m))
+    exit(0);
+
+  m->pid = 0;
+
+  __sync_synchronize();
+
+  __sync_lock_release(&m->locked);
+}
diff --git a/user/thread_sem.h b/user/thread_sem.h
new file mode 100644
index 0000000..0ea04e4
--- /dev/null
+++ b/user/thread_sem.h
@@ -0,0 +1,30 @@
+// Semaphores.
+#include "user/thread_cv.h"
+
+typedef struct __Zem_t {
+    int value;
+    struct condition cond;
+    struct thread_mutex lock;
+} Zem_t;
+
+// only one thread can call this
+void Zem_init(Zem_t *s, int value) {
+    s->value = value;
+    condition_init(&s->cond);
+    thread_mutex_init(&s->lock, "zem_t_mutex");
+}
+
+void Zem_wait(Zem_t *s) {
+    thread_mutex_lock(&s->lock);
+    while (s->value <= 0)
+        cond_wait(&s->cond, &s->lock);
+    s->value--;
+    thread_mutex_unlock(&s->lock);
+}
+
+void Zem_post(Zem_t *s) {
+    thread_mutex_lock(&s->lock);
+    s->value++;
+    cond_wakeup(&s->cond);
+    thread_mutex_unlock(&s->lock);
+}
diff --git a/user/thread_spinlock.h b/user/thread_spinlock.h
new file mode 100644
index 0000000..b85eac9
--- /dev/null
+++ b/user/thread_spinlock.h
@@ -0,0 +1,57 @@
+// Spinlock.
+#include "user/user.h"
+#include "kernel/types.h"
+
+struct thread_spinlock {
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  char *name;        // Name of lock.
+  int pid;   // The process holding the lock.
+};
+
+// Check whether this cpu is holding the lock.
+// Interrupts must be off.
+int
+thread_holding(struct thread_spinlock *lk)
+{
+  int r;
+  r = (lk->locked && lk->pid == getpid());
+  return r;
+}
+
+void
+thread_spin_init(struct thread_spinlock *lk, char *name)
+{
+  lk->name = name;
+  lk->locked = 0;
+  lk->pid = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_spin_lock(struct thread_spinlock *lk)
+{
+  if(thread_holding(lk))
+    exit(0);
+
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
+    ;
+
+  __sync_synchronize();
+
+  lk->pid = getpid();
+}
+
+// Release the lock.
+void
+thread_spin_unlock(struct thread_spinlock *lk)
+{
+  if(!thread_holding(lk))
+    exit(0);
+
+  lk->pid = 0;
+
+  __sync_lock_release(&lk->locked);
+}
diff --git a/user/threads.c b/user/threads.c
new file mode 100644
index 0000000..5d00e47
--- /dev/null
+++ b/user/threads.c
@@ -0,0 +1,77 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/thread_mutex.h"
+#include "user/thread_spinlock.h"
+
+struct balance {
+    char name[32];
+    int amount;
+};
+
+struct thread_spinlock lock;
+struct thread_mutex mlock;
+
+volatile int total_balance = 0;
+
+volatile unsigned int delay (unsigned int d) {
+   unsigned int i;
+   for (i = 0; i < d; i++) {
+       __asm volatile( "nop" ::: );
+   }
+
+   return i;
+}
+
+void do_work(void *arg){
+    int i;
+    int old;
+
+    struct balance *b = (struct balance*) arg;
+
+    thread_mutex_lock(&mlock);
+    printf( "Starting do_work: s:%s\n", b->name);
+    thread_mutex_unlock(&mlock);
+
+    for (i = 0; i < b->amount; i++) {
+        // lock and mlock will be implemented by you.
+        thread_spin_lock(&lock);
+        thread_mutex_lock(&mlock);
+        old = total_balance;
+        delay(100000);
+        if(old != total_balance)  printf("we will miss an update. old: %d total_balance: %d\n", old, total_balance);
+        total_balance = old + 1;
+        thread_spin_unlock(&lock);
+        thread_mutex_unlock(&mlock);
+    }
+
+    printf( "Done s:%x\n", b->name);
+
+    thread_exit();
+    return;
+}
+
+int main(int argc, char *argv[]) {
+
+  thread_spin_init(&lock, "lock");
+  thread_mutex_init(&mlock, "mlock");
+
+  struct balance b1 = {"b1", 3200};
+  struct balance b2 = {"b2", 2800};
+
+  void *s1, *s2;
+  int thread1, thread2, r1, r2;
+
+  s1 = malloc(4096); // 4096 is the PGSIZE defined in kernel/riscv.h
+  s2 = malloc(4096);
+
+  thread1 = thread_create(do_work, (void*)&b1, s1);
+  thread2 = thread_create(do_work, (void*)&b2, s2);
+
+  r1 = thread_join(thread1);
+  r2 = thread_join(thread2);
+
+  printf("Threads finished: (%d):%d, (%d):%d, shared balance:%d\n", thread1, r1, thread2, r2, total_balance);
+
+  exit(0);
+}
\ No newline at end of file
diff --git a/user/user.h b/user/user.h
index 4d398d5..5212322 100644
--- a/user/user.h
+++ b/user/user.h
@@ -22,6 +22,11 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int thread_create(void(*fcn)(void*), void *arg, void*stack);
+int thread_join(int thread_id);
+void thread_exit(void);
+void release_and_sleep(uint8* lock);
+void thread_wakeup(int thread_id);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..f9a4e7c 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,8 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("thread_create");
+entry("thread_join");
+entry("thread_exit");
+entry("release_and_sleep");
+entry("thread_wakeup");
