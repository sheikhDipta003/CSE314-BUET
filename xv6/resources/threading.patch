diff --git a/.vscode/settings.json b/.vscode/settings.json
new file mode 100644
index 0000000..21be27d
--- /dev/null
+++ b/.vscode/settings.json
@@ -0,0 +1,11 @@
+{
+    "files.associations": {
+        "assert.h": "c",
+        "defs.h": "c",
+        "riscv.h": "c",
+        "memlayout.h": "c",
+        "thread_spinlock.h": "c",
+        "param.h": "c",
+        "proc.h": "c"
+    }
+}
\ No newline at end of file
diff --git a/Makefile b/Makefile
index 39a99d7..b3038ca 100644
--- a/Makefile
+++ b/Makefile
@@ -132,6 +132,12 @@ UPROGS=\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
+	$U/_threads\
+	$U/_thread_spinlock\
+	$U/_thread_mutex\
+	$U/_producer_consumer\
+	$U/_thread_sem\
+	$U/_thread_cv\
 
 fs.img: mkfs/mkfs README $(UPROGS)
 	mkfs/mkfs fs.img README $(UPROGS)
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..11f4f21 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -106,6 +106,9 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
+int             thread_create(uint64 fcn, uint64 arg, uint64 stack);
+int             thread_join(int thread_id);
+void            thread_exit();
 
 // swtch.S
 void            swtch(struct context*, struct context*);
@@ -165,7 +168,10 @@ void            uvmfirst(pagetable_t, uchar *, uint);
 uint64          uvmalloc(pagetable_t, uint64, uint64, int);
 uint64          uvmdealloc(pagetable_t, uint64, uint64);
 int             uvmcopy(pagetable_t, pagetable_t, uint64);
+int             uvmmirror(pagetable_t, pagetable_t, uint64);
+int             uvmrangemirror(pagetable_t, pagetable_t, uint64, uint64);
 void            uvmfree(pagetable_t, uint64);
+void            freewalk(pagetable_t);
 void            uvmunmap(pagetable_t, uint64, uint64, int);
 void            uvmclear(pagetable_t, uint64);
 pte_t *         walk(pagetable_t, uint64, int);
diff --git a/kernel/exec.c b/kernel/exec.c
index e18bbb6..4d585af 100644
--- a/kernel/exec.c
+++ b/kernel/exec.c
@@ -19,120 +19,198 @@ int flags2perm(int flags)
     return perm;
 }
 
+//completes the work of the sys_exec() syscall
+//path -> executable file path: /usr/bin/cat
+//argv -> pointer to the argument strings needed for main() of that file [null terminated]
+//returns -1 if something goes wrong
+//but if all ok, then it begins executing that executable file in the new virtual address space of kernel
 int
 exec(char *path, char **argv)
 {
   char *s, *last;
   int i, off;
   uint64 argc, sz = 0, sp, ustack[MAXARG], stackbase;
+  //sz = 0 -> load the program segments into a new virtual address space (created later in this function) starting from virtual address 0
   struct elfhdr elf;
+
+  //an inode (short for "index node") is a fundamental data structure used to represent files. It contains metadata about a file, such as its type, permissions, size, and pointers to the data blocks that hold the file's content. Each inode is identified by a unique inode number, which is often used to reference the inode within the file system. Inodes are typically organized in an inode table or similar structure within the file system. This table allows the operating system to quickly look up and access inodes.
   struct inode *ip;
-  struct proghdr ph;
+  struct proghdr ph;    //program header data structure
   pagetable_t pagetable = 0, oldpagetable;
   struct proc *p = myproc();
 
-  begin_op();
+  begin_op();   //begin transaction
 
+  //namei() -> Look up and return the pointer to the inode for given path name of an executable file.
   if((ip = namei(path)) == 0){
-    end_op();
+    end_op();   //end transaction
     return -1;
   }
   ilock(ip);
 
-  // Check ELF header
-  if(readi(ip, 0, (uint64)&elf, 0, sizeof(elf)) != sizeof(elf))
+  // Read data from inode.
+  // Caller must hold ip->lock.
+  // If user_dst==1, then dst is a user virtual address;
+  // otherwise, dst is a kernel address.
+  // int readi(struct inode *ip, int user_dst, uint64 dst, uint off, uint n)
+  if(readi(ip, 0, (uint64)&elf, 0, sizeof(elf)) != sizeof(elf)) // Check ELF header
     goto bad;
 
+  //we read in from offset 0 [of the ipnode 'ip'] the elf header into local variable elf that points to a location in kernel-address-space
+
   if(elf.magic != ELF_MAGIC)
     goto bad;
 
+  //Now, this code is executing within a process, and that process has a virtual address space. If anything goes wrong, we have to return -1 and return to executing the code that is in that virt addr space.
+  //But if all ok, we are going to create a new user virtual address space, and load the executable file into that address space. So, now we are going to create that second virtual address space. The local variable pagetable will point to the newly created pagetable.
+  //The function proc_pagetable() needs to add a trapframe to the top of the new virtual address space and it needs to know which physical page to use for that particular page in the virtual address space.
+  //The executable file must be loaded into the 'code segment' of this new virtual address space
+
+  //proc_pagetable() -> Create a user page table for a given process, with no user memory, but with trampoline and trapframe pages.
   if((pagetable = proc_pagetable(p)) == 0)
     goto bad;
 
-  // Load program into memory.
+  //Load executable file into memory segment-by-segment. Each program segment may cover many pages.
+  //elf.phoff -> offset of the first program header
+  //elf.phnum -> total number of program headers
   for(i=0, off=elf.phoff; i<elf.phnum; i++, off+=sizeof(ph)){
+    //from 'off' offset of ipnode, read-in the program-segment of size 'sizeof(ph)' bytes into the local variable 'ph'
     if(readi(ip, 0, (uint64)&ph, off, sizeof(ph)) != sizeof(ph))
       goto bad;
     if(ph.type != ELF_PROG_LOAD)
       continue;
+
+    //when the program is loaded into memory, it will be allocated a memory of size memsz which is at least as large as filesz
     if(ph.memsz < ph.filesz)
       goto bad;
+
+    //check overflow, vaddr and memsz are unsigned integers
     if(ph.vaddr + ph.memsz < ph.vaddr)
       goto bad;
+
+    //check if the virtual address we will be loading the executable file into is page-aligned
     if(ph.vaddr % PGSIZE != 0)
       goto bad;
+
     uint64 sz1;
+
+    //Allocate PTEs and physical memory to grow virtual address space  from oldsz to
+    //newsz, which need not be page aligned. Returns new size or 0 on error. The newly created virtual address space must be at least large enough to hold the program segment
+    // uint64 uvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz, int xperm)
     if((sz1 = uvmalloc(pagetable, sz, ph.vaddr + ph.memsz, flags2perm(ph.flags))) == 0)
       goto bad;
+
+    //flags2perm()
+    //Each user-page is by default user-accessible and readable. With this helper function, we can specify whether this new virtual address space will be writable and/or executable.
+
+    //update local variable sz. why??
+    //Because we are executing A SINGLE PROGRAM DIVIDED INTO MANY PROGRAM SEGMENTS and we have created A SINGLE 'pagetable'/virtual-address-space for the whole program. So, each time this virt addr space grows, we must update its current size, because this will be the oldsize for the next program segment.
     sz = sz1;
+
+    //now we have created space for the current program segment in the new virtual address space. Next, load the bytes from the file to the virtual address space.
+    //ph.off -> where in the elf file, the bytes of current segment begin
+    //move the segment at location 'ph.vaddr' in virt addr space and update PTEs in 'pagetable'
     if(loadseg(pagetable, ph.vaddr, ip, ph.off, ph.filesz) < 0)
       goto bad;
   }
+
+  //we are done loading the executable file in new virt addr space corresponding to 'pagetable'
   iunlockput(ip);
   end_op();
   ip = 0;
 
   p = myproc();
-  uint64 oldsz = p->sz;
+  uint64 oldsz = p->sz;   //size of the virtual address space of current process
+
+  // now we have, in our new virtual address space, trampoline and trapframe, located at the top and all the program segments located at the bottom. But the final location of the ending position of the loaded segments ['sz'] may not be page aligned.
 
   // Allocate two pages at the next page boundary.
   // Make the first inaccessible as a stack guard.
   // Use the second as the user stack.
+  // From now on, 'the stack'/'stack' will refer to this user stack.
   sz = PGROUNDUP(sz);
   uint64 sz1;
   if((sz1 = uvmalloc(pagetable, sz, sz + 2*PGSIZE, PTE_W)) == 0)
     goto bad;
   sz = sz1;
+
+  //the guard page must be inaccessible to user, so make sure that stack never grows below stackbase
   uvmclear(pagetable, sz-2*PGSIZE);
-  sp = sz;
-  stackbase = sp - PGSIZE;
+  sp = sz;                  //top of the stack
+  stackbase = sp - PGSIZE;  //bottom of the stack
 
+  //this function is called from syscall sys_exec(), which passes an array, argv, of string pointers that point to the argument strings [originally provided by user] located at seaprate pages in kernel space
   // Push argument strings, prepare rest of stack in ustack.
+  //STACK GROWS DOWNWARD, THAT IS, FROM A HIGHER ADDRESS TO A LOWER ADDRESS
+  //this loop fetches all argument strings from argv array and pushes them onto the stack
   for(argc = 0; argv[argc]; argc++) {
     if(argc >= MAXARG)
       goto bad;
     sp -= strlen(argv[argc]) + 1;
     sp -= sp % 16; // riscv sp must be 16-byte aligned
+
+    //if stack grows below stackbase, that is, overflows, error
     if(sp < stackbase)
       goto bad;
+
+    //copy strings from argv[argc] to sp and update pagetable
     if(copyout(pagetable, sp, argv[argc], strlen(argv[argc]) + 1) < 0)
       goto bad;
+
+    //we want to save a pointer to the string just pushed onto the stack, hence the local variable ustack
     ustack[argc] = sp;
   }
   ustack[argc] = 0;
 
   // push the array of argv[] pointers.
-  sp -= (argc+1) * sizeof(uint64);
+  sp -= (argc+1) * sizeof(uint64);  //+1 for the null string in ustack
   sp -= sp % 16;
+
+  //if stack grows below stackbase, that is, overflows, error
   if(sp < stackbase)
     goto bad;
+
+  //copy strings from array ustack to sp and update pagetable
   if(copyout(pagetable, sp, (char *)ustack, (argc+1)*sizeof(uint64)) < 0)
     goto bad;
 
+  //now, sp points to the starting position of ustack array. Thus, when we will call the main() function for the executable file/program, we will pass argc in a0 and sp in a1
+
   // arguments to user main(argc, argv)
   // argc is returned via the system call return
   // value, which goes in a0.
   p->trapframe->a1 = sp;
 
   // Save program name for debugging.
+  //path-> usr/bin/echo
+  //               |
+  //              \|/
+  //              last
   for(last=s=path; *s; s++)
     if(*s == '/')
       last = s+1;
   safestrcpy(p->name, last, sizeof(p->name));
+
+  //now we are ready to switch from the old virtual address space where this code is running to the new virtual address space created previously for the program and make sure we start at the beginning of the new program
     
   // Commit to the user image.
   oldpagetable = p->pagetable;
   p->pagetable = pagetable;
   p->sz = sz;
   p->trapframe->epc = elf.entry;  // initial program counter = main
-  p->trapframe->sp = sp; // initial stack pointer
+  p->trapframe->sp = sp;          // initial stack pointer
   proc_freepagetable(oldpagetable, oldsz);
 
   return argc; // this ends up in a0, the first argument to main(argc, argv)
+  //even after return of the sys_exec(), this user program continues execution starting from elf.entry
+  //the new program executes with all the files that were open in the previous program still open and in the same cwd since the fields ofile and cwd of myproc() is unchanged
 
  bad:
+  //since we don't know at which point we got a 'bad' result, check if we have reached far enough to allocate a pagetable. If yes, free that pagetable as well as the data pages of total size 'sz'
   if(pagetable)
     proc_freepagetable(pagetable, sz);
+
+  //if inode for the executable file still open
   if(ip){
     iunlockput(ip);
     end_op();
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..41e2739 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -13,7 +13,9 @@ struct proc proc[NPROC];
 struct proc *initproc;
 
 int nextpid = 1;
+int next_mem_id = 1;
 struct spinlock pid_lock;
+struct spinlock mem_id_lock;
 
 extern void forkret(void);
 static void freeproc(struct proc *p);
@@ -102,10 +104,24 @@ allocpid()
   return pid;
 }
 
+int
+allocmemid()
+{
+  int mem_id;
+
+  acquire(&mem_id_lock);
+  mem_id = next_mem_id;
+  next_mem_id = next_mem_id + 1;
+  release(&mem_id_lock);
+
+  return mem_id;
+}
+
 // Look in the process table for an UNUSED proc.
 // If found, initialize state required to run in the kernel,
 // and return with p->lock held.
 // If there are no free procs, or a memory allocation fails, return 0.
+// allocates a new address space for any free proc structure that it can find. allocates trapframe, trampoline and user stack pages in that new address space. updates proc structure fields as necessary and returns the updated proc structure.
 static struct proc*
 allocproc(void)
 {
@@ -123,6 +139,7 @@ allocproc(void)
 
 found:
   p->pid = allocpid();
+  p->mem_id = allocmemid();
   p->state = USED;
 
   // Allocate a trapframe page.
@@ -131,18 +148,29 @@ found:
     release(&p->lock);
     return 0;
   }
+  //p->trapframe -> physcial address of the trapframe [in the actual physical ram of the system xv6 is running on]
 
   // An empty user page table.
+  acquire(&p->memlock);
   p->pagetable = proc_pagetable(p);
+
+  //we have the physical address of p->trapframe, but we don't have a pagetable for p. Thus, we will call proc_pagetable(p). This function will allocate an empty pagetable by calling kalloc(). Fill the pagetable with 0. Finally, update corresponding PTEs of p->trapframe and trampoline page with their va[in the address space of 'p']-->pa[in actual physical memory, which corresponds to kernel address space] mapping.
+
   if(p->pagetable == 0){
     freeproc(p);
     release(&p->lock);
+    release(&p->memlock);
     return 0;
   }
+  else  release(&p->memlock);
 
   // Set up new context to start executing at forkret,
   // which returns to user space.
+  //void* memset(void *dst, int c, uint n)
+  //fill 'n' bytes of the location starting from 'dst' with 'c'
   memset(&p->context, 0, sizeof(p->context));
+  //this clears all the registers in process 'p'
+
   p->context.ra = (uint64)forkret;
   p->context.sp = p->kstack + PGSIZE;
 
@@ -158,9 +186,19 @@ freeproc(struct proc *p)
   if(p->trapframe)
     kfree((void*)p->trapframe);
   p->trapframe = 0;
-  if(p->pagetable)
-    proc_freepagetable(p->pagetable, p->sz);
+  acquire(&p->memlock);
+  if(p->pagetable){
+    if(!p->is_thread) proc_freepagetable(p->pagetable, p->sz);
+    else{
+      uvmunmap(p->pagetable, TRAMPOLINE, 1, 0);
+      uvmunmap(p->pagetable, TRAPFRAME, 1, 0);
+      if(p->sz > 0)
+        uvmunmap(p->pagetable, 0, PGROUNDUP(p->sz)/PGSIZE, 0);
+      freewalk(p->pagetable);
+    }
+  }
   p->pagetable = 0;
+  release(&p->memlock);
   p->sz = 0;
   p->pid = 0;
   p->parent = 0;
@@ -239,7 +277,9 @@ userinit(void)
   
   // allocate one user page and copy initcode's instructions
   // and data into it.
+  acquire(&p->memlock);
   uvmfirst(p->pagetable, initcode, sizeof(initcode));
+  release(&p->memlock);
   p->sz = PGSIZE;
 
   // prepare for the very first "return" from kernel to user.
@@ -261,16 +301,37 @@ growproc(int n)
 {
   uint64 sz;
   struct proc *p = myproc();
+  acquire(&p->memlock);
 
   sz = p->sz;
   if(n > 0){
     if((sz = uvmalloc(p->pagetable, sz, sz + n, PTE_W)) == 0) {
+      release(&p->memlock);
       return -1;
     }
   } else if(n < 0){
     sz = uvmdealloc(p->pagetable, sz, sz + n);
   }
   p->sz = sz;
+
+  struct proc *q;
+  for(q = proc; q < &proc[NPROC]; q++){
+    if(q->mem_id == p->mem_id && q != p){
+      if(n >= 0){
+        acquire(&q->memlock);
+        uvmrangemirror(p->pagetable, q->pagetable, q->sz, sz);
+        release(&q->memlock);
+      }
+      else{
+        acquire(&q->memlock);
+        uvmunmap(q->pagetable, PGROUNDUP(sz), (PGROUNDUP(q->sz)-PGROUNDUP(sz))/PGSIZE, 1);
+        release(&q->memlock);
+      }
+      q->sz = sz;
+    }
+  }
+
+  release(&p->memlock);
   return 0;
 }
 
@@ -287,16 +348,26 @@ fork(void)
   if((np = allocproc()) == 0){
     return -1;
   }
+  //by calling allocproc(), we have created a new virtual address space and a new empty pagetable, we have allocated space for trampoline and trapframe page and added both of their va<-->pa maping into the empty pagetable and finally we have created a user stack for 'np' as well as updated its sp to point to the top of the now empty stack.
+
+  //next we have to copy the parent's data pages [from heap memory] to the new virtual address space for the child. We can get the size of these data pages from p->sz
 
-  // Copy user memory from parent to child.
+  //Copy user memory from parent to child.
+  //every data page from the parent process 'p' is copied and added to the child's virtual address space
+  acquire(&p->memlock);
+  acquire(&np->memlock);
   if(uvmcopy(p->pagetable, np->pagetable, p->sz) < 0){
     freeproc(np);
     release(&np->lock);
+    release(&p->memlock);
+    release(&np->memlock);
     return -1;
   }
   np->sz = p->sz;
 
   // copy saved user registers.
+  // when this function is called via syscall sys_fork(), which is called by the parent process, the parent process saves all user registers and epc to p->trapframe. Now, since we used kalloc() for allocating np->trapframe, np->trapframe and p->trapframe point to different locations in the actual physical memory. Thus, we have to copy the VALUES of user registers and epc to the location pointed to by np->trapframe. Copy epc so that the child process starts from the same line number that the parent process resumes after the syscall.
+  // Keep in mind that previously, when we called np = allocproc(), allocproc() only ALLOCATED PHYSICAL MEM for np->trapframe and added va<-->pa mapping to np->pagetable; that is, np->trapframe has been empty until now
   *(np->trapframe) = *(p->trapframe);
 
   // Cause fork to return 0 in the child.
@@ -325,6 +396,105 @@ fork(void)
   return pid;
 }
 
+int
+thread_create(uint64 fcn, uint64 arg, uint64 stack)
+{
+  int i, pid;
+  struct proc *np;
+  struct proc *p = myproc();
+
+  if((np = allocproc()) == 0){
+    return -1;
+  }
+
+  acquire(&p->memlock);
+  release(&np->memlock);
+  if(uvmmirror(p->pagetable, np->pagetable, p->sz) < 0){
+    freeproc(np);
+    release(&np->lock);
+    release(&p->memlock);
+    release(&np->memlock);
+    return -1;
+  }
+
+  np->sz = p->sz;
+  *(np->trapframe) = *(p->trapframe);
+  np->trapframe->a0 = 0;
+  np->trapframe->epc = fcn;
+  np->trapframe->sp = stack + PGSIZE;
+  np->is_thread = 1;
+  np->mem_id = p->mem_id;
+
+  p->trapframe->a0 = arg;
+
+  for(i = 0; i < NOFILE; i++)
+    if(p->ofile[i])
+      np->ofile[i] = filedup(p->ofile[i]);
+  np->cwd = idup(p->cwd);
+
+  safestrcpy(np->name, p->name, sizeof(p->name));
+
+  pid = np->pid;
+
+  release(&np->lock);
+
+  acquire(&wait_lock);
+  np->parent = p;
+  release(&wait_lock);
+
+  acquire(&np->lock);
+  np->state = RUNNABLE;
+  release(&np->lock);
+
+  return pid;
+}
+
+int
+thread_join(int thread_id)
+{
+  struct proc *pp;
+  int havekids, pid;
+  struct proc *p = myproc();
+
+  acquire(&wait_lock);
+
+  for(;;){
+    // Scan through table looking for exited children.
+    havekids = 0;
+    for(pp = proc; pp < &proc[NPROC]; pp++){
+      if(pp->parent == p && pp->pid == thread_id){
+        // make sure the child isn't still in exit() or swtch().
+        acquire(&pp->lock);
+
+        havekids = 1;
+        if(pp->state == ZOMBIE){
+          // Found one.
+          pid = pp->pid;
+          // if(addr != 0 && copyout(p->pagetable, addr, (char *)&pp->xstate, sizeof(pp->xstate)) < 0) {
+          //   release(&pp->lock);
+          //   release(&wait_lock);
+          //   return -1;
+          // }
+          freeproc(pp);
+          release(&pp->lock);
+          release(&wait_lock);
+          return pid;
+        }
+        release(&pp->lock);
+      }
+    }
+
+    // No point waiting if we don't have any children.
+    if(!havekids || killed(p)){
+      release(&wait_lock);
+      return -1;
+    }
+
+    // Wait for a child to exit.
+    sleep(p, &wait_lock);  //DOC: wait-sleep
+  }
+}
+
 // Pass p's abandoned children to init.
 // Caller must hold wait_lock.
 void
@@ -340,6 +510,48 @@ reparent(struct proc *p)
   }
 }
 
+void
+thread_exit()
+{
+  struct proc *p = myproc();
+
+  if(p == initproc)
+    panic("init exiting");
+
+  // Close all open files.
+  for(int fd = 0; fd < NOFILE; fd++){
+    if(p->ofile[fd]){
+      struct file *f = p->ofile[fd];
+      fileclose(f);
+      p->ofile[fd] = 0;
+    }
+  }
+
+  begin_op();
+  iput(p->cwd);
+  end_op();
+  p->cwd = 0;
+
+  acquire(&wait_lock);
+
+  // Give any children to init.
+  reparent(p);
+
+  // Parent might be sleeping in wait().
+  wakeup(p->parent);
+
+  acquire(&p->lock);
+
+  p->xstate = 0;
+  p->state = ZOMBIE;
+
+  release(&wait_lock);
+
+  // Jump into the scheduler, never to return.
+  sched();
+  panic("zombie exit");
+}
+
 // Exit the current process.  Does not return.
 // An exited process remains in the zombie state
 // until its parent calls wait().
@@ -408,12 +620,15 @@ wait(uint64 addr)
         if(pp->state == ZOMBIE){
           // Found one.
           pid = pp->pid;
+          acquire(&p->memlock);
           if(addr != 0 && copyout(p->pagetable, addr, (char *)&pp->xstate,
                                   sizeof(pp->xstate)) < 0) {
             release(&pp->lock);
             release(&wait_lock);
+            release(&p->memlock);
             return -1;
           }
+          else  release(&p->memlock);
           freeproc(pp);
           release(&pp->lock);
           release(&wait_lock);
@@ -561,6 +776,31 @@ sleep(void *chan, struct spinlock *lk)
   acquire(lk);
 }
 
+void
+cond_sleep(struct spinlock *lk)
+{
+  struct proc *p = myproc();
+  
+  // Must acquire p->lock in order to
+  // change p->state and then call sched.
+  // Once we hold p->lock, we can be
+  // guaranteed that we won't miss any wakeup
+  // (wakeup locks p->lock),
+  // so it's okay to release lk.
+
+  acquire(&p->lock);  //DOC: sleeplock1
+  release(lk);
+
+  // Go to sleep.
+  p->state = SLEEPING;
+
+  sched();
+
+  // Reacquire original lock.
+  release(&p->lock);
+  // acquire(lk);
+}
+
 // Wake up all processes sleeping on chan.
 // Must be called without any p->lock.
 void
@@ -630,7 +870,9 @@ either_copyout(int user_dst, uint64 dst, void *src, uint64 len)
 {
   struct proc *p = myproc();
   if(user_dst){
+    acquire(&p->memlock);
     return copyout(p->pagetable, dst, src, len);
+    release(&p->memlock);
   } else {
     memmove((char *)dst, src, len);
     return 0;
@@ -645,7 +887,9 @@ either_copyin(void *dst, int user_src, uint64 src, uint64 len)
 {
   struct proc *p = myproc();
   if(user_src){
+    acquire(&p->memlock);
     return copyin(p->pagetable, dst, src, len);
+    release(&p->memlock);
   } else {
     memmove(dst, (char*)src, len);
     return 0;
diff --git a/kernel/proc.h b/kernel/proc.h
index d021857..7bd3414 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -104,4 +104,7 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+  struct spinlock memlock;	  // find places to set and release the locks
+  int is_thread;               // if it is thread
+  int mem_id;                   // All threads will have the same physical pages with the mothrer, hence the same memory ID
 };
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..6a81db3 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,9 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_thread_create(void);
+extern uint64 sys_thread_join(void);
+extern uint64 sys_thread_exit(void);
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +129,9 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_thread_create]   sys_thread_create,
+[SYS_thread_join]   sys_thread_join,
+[SYS_thread_exit]   sys_thread_exit,
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..d6a9cf3 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,6 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_thread_create  22
+#define SYS_thread_join    23
+#define SYS_thread_exit    24
diff --git a/kernel/sysfile.c b/kernel/sysfile.c
index 16b668c..b56280a 100644
--- a/kernel/sysfile.c
+++ b/kernel/sysfile.c
@@ -431,36 +431,51 @@ sys_chdir(void)
   return 0;
 }
 
+// gets all the arguments[passed as an array of strings] from the address-space of the process that invokes this syscall
 uint64
 sys_exec(void)
 {
   char path[MAXPATH], *argv[MAXARG];
+  //at this point, argv is just an empty array of size MAXARG; located in kernel-address-space.
+  //the goal of this function is to copy all the args currently residing in user-process-address-space to kernel-address-space, that is, gradually fillup argv array. And after filling it with the last user arg, set remaining slots in argv to null.
   int i;
   uint64 uargv, uarg;
 
-  argaddr(1, &uargv);
+  argaddr(1, &uargv);   //copy virtual address[user-space] of the argument array, provided as the second parameter to exec() syscall, to uargv. So, uargv now points to the starting position of the arguments array provided.
+
+  //copy maximum 'MAXPATH' characters into 'path' from the first argument provided.
   if(argstr(0, path, MAXPATH) < 0) {
     return -1;
   }
-  memset(argv, 0, sizeof(argv));
-  for(i=0;; i++){
-    if(i >= NELEM(argv)){
+  memset(argv, 0, sizeof(argv));  //sets all entries of argv to null
+  for(i=0;; i++){              //loop through all the args
+    if(i >= NELEM(argv)){     //'bad' if we have gone past the number of args that can be accommodated
       goto bad;
     }
+
+    //goto the argument at i-th offset from the starting position of uargv and store the location in uarg
     if(fetchaddr(uargv+sizeof(uint64)*i, (uint64*)&uarg) < 0){
       goto bad;
     }
-    if(uarg == 0){
+    if(uarg == 0){    //if we got the last argument provided by the user, set the argv element to null and break the loop
       argv[i] = 0;
       break;
     }
+
+    //as mentioned earlier, the location pointed to by uarg is a virtual address of user process. We need to move them to kernel memory. So, allocate an entire page for storing the current argument pointed to by uarg.
     argv[i] = kalloc();
     if(argv[i] == 0)
       goto bad;
+
+    //now we are done allocating a page in kernel-address-space for argv[i], but the page is empty, we haven't fetched the argument yet. That's what we are doing next.
+
+    //int fetchstr(uint64 addr, char *buf, int max)
+    //There is a string located at virtual adrress addr in current user-proces. Fetch 'max' number of characters from that string into 'buf'
     if(fetchstr(uarg, argv[i], PGSIZE) < 0)
       goto bad;
   }
 
+  //now we have fetched both the path to run the requested executable file and the arguments needed to run that file's main() function. Next, execute the file by calling exec() function. The number of arguments needed for main() function of the program will be returned from exec()
   int ret = exec(path, argv);
 
   for(i = 0; i < NELEM(argv) && argv[i] != 0; i++)
@@ -469,6 +484,7 @@ sys_exec(void)
   return ret;
 
  bad:
+  //in case of unexpected errors, free all the pages created for storing the user-provided arguments
   for(i = 0; i < NELEM(argv) && argv[i] != 0; i++)
     kfree(argv[i]);
   return -1;
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..2bddbf0 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,26 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+uint64
+sys_thread_create(void) {
+  uint64 fcn, arg, stack;
+  argaddr(0, &fcn);
+  argaddr(1, &arg);
+  argaddr(2, &stack);
+
+  return thread_create(fcn, arg, stack);
+}
+
+uint64
+sys_thread_join(void){
+  int tid;
+  argint(0, &tid);
+  return thread_join(tid);
+}
+
+uint64
+sys_thread_exit(void){
+  thread_exit();
+  return 0;
+}
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..36bb18c 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -302,6 +302,7 @@ uvmfree(pagetable_t pagetable, uint64 sz)
 // physical memory.
 // returns 0 on success, -1 on failure.
 // frees any allocated pages on failure.
+// sz -> size of the old virtual address space
 int
 uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
 {
@@ -332,6 +333,57 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   return -1;
 }
 
+//Similar to uvmcopy() except that it doesn't use kalloc() i.e. doesn't allocate new physical pages
+int
+uvmmirror(pagetable_t old, pagetable_t new, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = 0; i < sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmcopy: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmcopy: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    if(mappages(new, i, PGSIZE, (uint64)pa, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+int
+uvmrangemirror(pagetable_t old, pagetable_t new, uint64 sz_old, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = PGROUNDUP(sz_old); i < sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmcopy: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmcopy: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    if(mappages(new, i, PGSIZE, (uint64)pa, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, PGROUNDUP(sz_old), (i - PGROUNDUP(sz_old)) / PGSIZE, 1);
+  return -1;
+}
+
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
 void
diff --git a/user/producer_consumer.c b/user/producer_consumer.c
new file mode 100644
index 0000000..91156eb
--- /dev/null
+++ b/user/producer_consumer.c
@@ -0,0 +1,110 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+
+struct queue{
+	int arr[16];
+	int front;
+	int rear;
+	int size;
+};
+queue(struct queue q)
+{
+    q.front = 0;
+    q.rear = 0;
+    q.size = 0;
+}
+void push(struct queue q, int x)
+{
+    q.arr[q.rear] = x;
+    q.rear = (q.rear+1)%16;
+    q.size++;
+}
+int front(struct queue q)
+{
+    if(q.size==0)
+        return -1;
+    return q.arr[q.front];
+}
+void pop(struct queue q)
+{
+    if(q.size==0) return;
+    q.front = (q.front+1)%16;
+    q.size--;
+}
+struct queue q;
+// a mutex object lock 
+// a semaphore object empty
+// a semaphore object full
+
+void init_semaphore()
+{
+	// initialize mutex lock
+	// initialize semaphore empty with 5
+	// initialize semaphore full with 0
+
+}
+
+void * ProducerFunc(void * arg)
+{	
+	printf("%s\n",(char*)arg);
+	int i;
+	for(i=1;i<=10;i++)
+	{
+		// wait for semphore empty
+
+		// wait for mutex lock
+		
+		sleep(1);	
+		push(q, i);
+		printf("producer produced item %d\n",i);
+		
+		// unlock mutex lock	
+		// post semaphore full
+	}
+}
+
+void * ConsumerFunc(void * arg)
+{
+	printf("%s\n",(char*)arg);
+	int i;
+	for(i=1;i<=10;i++)
+	{	
+		// wait for semphore full
+		// wait for mutex lock
+ 		
+			
+		sleep(1);
+		int item = front(q);
+		pop(q);
+		printf("consumer consumed item %d\n",item);	
+
+
+		// unlock mutex lock
+		// post semaphore empty		
+	}
+}
+
+int main(void)
+{	
+	
+	init_semaphore();
+	
+	char * message1 = "i am producer";
+	char * message2 = "i am consumer";
+
+
+	void *s1, *s2;
+  	int thread1, thread2, r1, r2;
+
+  	s1 = malloc(4096);
+  	s2 = malloc(4096);
+
+  	thread1 = thread_create(ProducerFunc, (void*)message1, s1);
+  	thread2 = thread_create(ConsumerFunc, (void*)message2, s2); 
+
+  	r1 = thread_join(thread1);
+  	r2 = thread_join(thread2);	
+	
+	exit(0);
+}
diff --git a/user/thread_cv.c b/user/thread_cv.c
new file mode 100644
index 0000000..c498466
--- /dev/null
+++ b/user/thread_cv.c
@@ -0,0 +1,36 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "kernel/proc.h"
+#include "kernel/param.h"
+#include "kernel/memlayout.h"
+#include "kernel/riscv.h"
+#include "kernel/spinlock.h"
+#include "kernel/defs.h"
+#include "user/user.h"
+#include "user/thread_cv.h"
+
+struct queue q;
+
+//  ----------- pseudo code --------
+//  void wait (condition *cv, mutex *mx) 
+//   {
+//     mutex_acquire(&c->listLock);  /* protect the queue */
+//     enqueue (&c->next, &c->prev, thr_self()); /* enqueue */
+//     mutex_release (&c->listLock); /* we're done with the list */
+  
+//     /* The suspend and release_mutex() operation should be atomic */
+//     release_mutex (mx));
+//     thr_suspend (self);  /* Sleep 'til someone wakes us */
+  
+//     mutex_acquire (mx); /* Woke up -- our turn, get resource lock */
+  
+//     return;
+//   }
+
+void
+cond_wait(struct condition *cv, struct spinlock *lk)
+{
+    acquire(&cv->mx);
+
+    release(&cv->mx);
+}
\ No newline at end of file
diff --git a/user/thread_cv.h b/user/thread_cv.h
new file mode 100644
index 0000000..e5576a6
--- /dev/null
+++ b/user/thread_cv.h
@@ -0,0 +1,36 @@
+struct queue{
+	int arr[16];
+	int front;
+	int rear;
+	int size;
+};
+
+queue(struct queue q)
+{
+    q.front = 0;
+    q.rear = 0;
+    q.size = 0;
+}
+void push(struct queue q, int x)
+{
+    q.arr[q.rear] = x;
+    q.rear = (q.rear+1)%16;
+    q.size++;
+}
+int front(struct queue q)
+{
+    if(q.size==0)
+        return -1;
+    return q.arr[q.front];
+}
+void pop(struct queue q)
+{
+    if(q.size==0) return;
+    q.front = (q.front+1)%16;
+    q.size--;
+}
+
+struct condition {
+    struct queue Q;
+    struct spinlock mx; /*protects queue; This semaphore should be a spin-lock since it will only be held for very short periods of time. */
+};
\ No newline at end of file
diff --git a/user/thread_mutex.c b/user/thread_mutex.c
new file mode 100644
index 0000000..d87caf8
--- /dev/null
+++ b/user/thread_mutex.c
@@ -0,0 +1,86 @@
+// Mutual exclusion spin locks.
+// initialize the mutex to the correct initial state (void thread_mutex_init(struct thread_mutex *m))
+// a function to acquire a mutex (void thread_mutex_lock(struct thread_mutex *m))
+// a function to release it void thread_mutex_unlock(struct thread_mutex *m)
+
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "kernel/proc.h"
+#include "kernel/param.h"
+#include "kernel/memlayout.h"
+#include "kernel/riscv.h"
+#include "user/user.h"
+#include "user/thread_mutex.h"
+
+void
+thread_mutex_init(struct thread_mutex *m, char *name)
+{
+  m->name = name;
+  m->locked = 0;
+  m->p = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_mutex_lock(struct thread_mutex *m)
+{
+//   push_off(); // disable interrupts to avoid deadlock.
+  if(thread_holding_mutex(m))
+    panic("thread_mutex_lock");
+
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &m->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&m->locked, 1) != 0)
+    sleep(1);
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Record info about lock acquisition for holding() and debugging.
+  m->p = myproc();
+}
+
+// Release the lock.
+void
+thread_mutex_unlock(struct thread_mutex *m)
+{
+  if(!thread_holding_mutex(m))
+    panic("thread_mutex_unlock");
+
+  m->p = 0;
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to m->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &m->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&m->locked);
+
+//   pop_off();
+}
+
+// Check whether this cpu is holding the lock.
+// Interrupts must be off.
+int
+thread_holding_mutex(struct thread_mutex *m)
+{
+  int r;
+  r = (m->locked && m->p == getpid());
+  return r;
+}
diff --git a/user/thread_mutex.h b/user/thread_mutex.h
new file mode 100644
index 0000000..079d8c9
--- /dev/null
+++ b/user/thread_mutex.h
@@ -0,0 +1,9 @@
+// Mutual exclusion lock.
+struct thread_mutex {
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  char *name;        // Name of lock.
+  struct proc *p;   // The process holding the lock.
+};
+
diff --git a/user/thread_sem.c b/user/thread_sem.c
new file mode 100644
index 0000000..1cb9924
--- /dev/null
+++ b/user/thread_sem.c
@@ -0,0 +1,8 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "kernel/proc.h"
+#include "kernel/param.h"
+#include "kernel/memlayout.h"
+#include "kernel/riscv.h"
+#include "user/user.h"
+#include "user/thread_mutex.h"
\ No newline at end of file
diff --git a/user/thread_sem.h b/user/thread_sem.h
new file mode 100644
index 0000000..e69de29
diff --git a/user/thread_spinlock.c b/user/thread_spinlock.c
new file mode 100644
index 0000000..a9264eb
--- /dev/null
+++ b/user/thread_spinlock.c
@@ -0,0 +1,86 @@
+// Mutual exclusion spin locks.
+// initialize the lock to the correct initial state (void thread_spin_init(struct thread_spinlock *lk))
+// a function to acquire a lock (void thread_spin_lock(struct thread_spinlock *lk))
+// a function to release it void thread_spin_unlock(struct thread_spinlock *lk)
+
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "kernel/proc.h"
+#include "kernel/param.h"
+#include "kernel/memlayout.h"
+#include "kernel/riscv.h"
+#include "user/user.h"
+#include "user/thread_spinlock.h"
+
+void
+thread_spin_init(struct thread_spinlock *lk, char *name)
+{
+  lk->name = name;
+  lk->locked = 0;
+  lk->p = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_spin_lock(struct thread_spinlock *lk)
+{
+//   push_off(); // disable interrupts to avoid deadlock.
+  if(thread_holding(lk))
+    panic("thread_spin_lock");
+
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &lk->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
+    ;
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Record info about lock acquisition for holding() and debugging.
+  lk->p = myproc();
+}
+
+// Release the lock.
+void
+thread_spin_unlock(struct thread_spinlock *lk)
+{
+  if(!thread_holding(lk))
+    panic("thread_spin_unlock");
+
+  lk->p = 0;
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&lk->locked);
+
+//   pop_off();
+}
+
+// Check whether this cpu is holding the lock.
+// Interrupts must be off.
+int
+thread_holding(struct thread_spinlock *lk)
+{
+  int r;
+  r = (lk->locked && lk->p == getpid());
+  return r;
+}
diff --git a/user/thread_spinlock.h b/user/thread_spinlock.h
new file mode 100644
index 0000000..14b1e17
--- /dev/null
+++ b/user/thread_spinlock.h
@@ -0,0 +1,9 @@
+// Mutual exclusion lock.
+struct thread_spinlock {
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  char *name;        // Name of lock.
+  struct proc *p;   // The process holding the lock.
+};
+
diff --git a/user/threads.c b/user/threads.c
new file mode 100644
index 0000000..f2fcf6d
--- /dev/null
+++ b/user/threads.c
@@ -0,0 +1,68 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+
+struct balance {
+    char name[32];
+    int amount;
+};
+
+volatile int total_balance = 0;
+
+volatile unsigned int delay (unsigned int d) {
+   unsigned int i;
+   for (i = 0; i < d; i++) {
+       __asm volatile( "nop" ::: );
+   }
+
+   return i;
+}
+
+void do_work(void *arg){
+    int i;
+    int old;
+
+    struct balance *b = (struct balance*) arg;
+    printf( "Starting do_work: s:%s\n", b->name);
+
+    for (i = 0; i < b->amount; i++) {
+        // lock and mlock will be implemented by you.
+         // thread_spin_lock(&lock);
+         // thread_mutex_lock(&mlock);
+         old = total_balance;
+         delay(100000);
+	 // if(old != total_balance)  printf("we will miss an update. old: %d total_balance: %d\n", old, total_balance);
+         total_balance = old + 1;
+         //thread_spin_unlock(&lock);
+         // thread_mutex_lock(&mlock);
+
+    }
+
+    printf( "Done s:%x\n", b->name);
+
+    thread_exit();
+    return;
+}
+
+int main(int argc, char *argv[]) {
+
+  struct balance b1 = {"b1", 3200};
+  struct balance b2 = {"b2", 2800};
+
+  void *s1, *s2;
+  int thread1, thread2, r1, r2;
+
+  s1 = malloc(4096); // 4096 is the PGSIZE defined in kernel/riscv.h
+  s2 = malloc(4096);
+
+  thread1 = thread_create(do_work, (void*)&b1, s1);
+  thread2 = thread_create(do_work, (void*)&b2, s2);
+
+  r1 = thread_join(thread1);
+  r2 = thread_join(thread2);
+
+  printf("Threads finished: (%d):%d, (%d):%d, shared balance:%d\n",
+      thread1, r1, thread2, r2, total_balance);
+
+  exit(0);
+}
\ No newline at end of file
diff --git a/user/user.h b/user/user.h
index 4d398d5..2bfd94f 100644
--- a/user/user.h
+++ b/user/user.h
@@ -22,6 +22,9 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int thread_create(void(*fcn)(void*), void *arg, void*stack);
+int thread_join(int thread_id);
+void thread_exit(void);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..a334aa7 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,6 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("thread_create");
+entry("thread_join");
+entry("thread_exit");
